{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef776710-d7c9-4bf5-b4f4-2e0101ea0e56",
   "metadata": {},
   "source": [
    "### columns info\n",
    " - ACADEMIC_STAT_CODE : 중도탈락 여부\n",
    " - ADMISSION : 입학 전형\n",
    " - AGE : 나이\n",
    " - ATTENDANCE : 출석률\n",
    " - DOUBLE_MAJOR : 복수전공 여부\n",
    " - GRADE : 평균학점\n",
    " - INCOME_QUINTILE: 소득분위(5분위)\n",
    " - OCCP_GRP_1 : 학과 계열\n",
    " - PREPARE_ATTENDANCE : 동일 나이 대비 출석률\n",
    " - PREPARE_GRADE : 동일 나이 대비 평균학점\n",
    " - PREPARE_join_1years_ago\tPREPARE_join_2years_ago\tPREPARE_join_3years_ago\tPREPARE_join_4years_ago\tPREPARE_join_this_year \n",
    "   : 동일나이 대비 년도별 교내 프로그램 참가 횟수\n",
    " - STUDENT_ID : 학생 고유 번호\n",
    " - TOTAL_JOIN : 교내프로그램 총 참가 횟수\n",
    " - TOTAL_OFF : 총 휴학 횟수\n",
    " - UNI_DIST : 거주지와 대학간의 거리\n",
    " - join_1years_ago join_2years_ago join_3years_ago join_4years_ago join_this_year\n",
    "   : 년도별 교내프로그램 참가 횟수\n",
    " - off_1years_ago\toff_2years_ago\toff_3years_ago\toff_4years_ago\toff_this_year\n",
    "   : 년도별 휴학 여부"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd85da4-8045-4ae9-8409-5e9a034a5489",
   "metadata": {},
   "source": [
    "## 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40fb4885-edde-413b-9185-6c8d7f8818d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime as dt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e77c139-81a7-48fc-92f9-cafe037faebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_100(a, b):\n",
    "    print( round( (a/(a+b))*100,2), \"%\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9577906-1d4d-48af-a1f8-4d607394af70",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_student = pd.read_csv('./temp_data/save_scaled_student.csv',encoding='utf-8').rename(columns= {'Unnamed: 0': 'index'}).set_index('index',drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0fdcba3-19cf-4fc4-a87d-19366f8814be",
   "metadata": {},
   "source": [
    "## 훈련데이터와 검증데이터로 분리\n",
    " - 데이터는 8:1:1로 분리함\n",
    " - 8은 학습데이터, 1은 1차 검증데이터\n",
    " - 마지막 1은 feature importance를 확인한 후 학습데이터와 1차 검증데이터를 학습시킨 모델을 완성시킨 후 모델을 검증할 최종 검증 데이터 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "224e2a53-bb81-4dbc-8207-fa7f1f4f26d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACADEMIC_STAT_CODE    15738\n",
      "dtype: int64\n",
      "ACADEMIC_STAT_CODE    746\n",
      "dtype: int64\n",
      "ACADEMIC_STAT_CODE    1970\n",
      "dtype: int64\n",
      "ACADEMIC_STAT_CODE    91\n",
      "dtype: int64\n",
      "ACADEMIC_STAT_CODE    1978\n",
      "dtype: int64\n",
      "ACADEMIC_STAT_CODE    83\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "label = 'ACADEMIC_STAT_CODE'\n",
    "\n",
    "x_train, temp_x_test, y_train, temp_y_test = train_test_split(scaled_student[scaled_student.columns.drop(label)], scaled_student[label],\\\n",
    "                                                              test_size=0.2, random_state=42)\n",
    "\n",
    "x_test_1st, x_test_2nd, y_test_1st, y_test_2nd = train_test_split(temp_x_test, temp_y_test, test_size=0.5, random_state=42)\n",
    "\n",
    "train_0 = y_train.to_frame().loc[y_train.to_frame()['ACADEMIC_STAT_CODE'] == '유지'].count()\n",
    "train_1 = y_train.to_frame().loc[y_train.to_frame()['ACADEMIC_STAT_CODE'] == '탈락'].count()\n",
    "test_1st_0 = y_test_1st.to_frame().loc[y_test_1st.to_frame()['ACADEMIC_STAT_CODE'] == '유지'].count()\n",
    "test_1st_1 = y_test_1st.to_frame().loc[y_test_1st.to_frame()['ACADEMIC_STAT_CODE'] == '탈락'].count()\n",
    "test_2nd_0 = y_test_2nd.to_frame().loc[y_test_2nd.to_frame()['ACADEMIC_STAT_CODE'] == '유지'].count()\n",
    "test_2nd_1 = y_test_2nd.to_frame().loc[y_test_2nd.to_frame()['ACADEMIC_STAT_CODE'] == '탈락'].count()\n",
    "\n",
    "x_train.to_csv('./temp_data/save_x_train.csv',index = True)\n",
    "y_train.to_csv('./temp_data/save_y_train.csv',index = True)\n",
    "x_test_1st.to_csv('./temp_data/save_x_test_1st.csv',index = True)\n",
    "y_test_1st.to_csv('./temp_data/save_y_test_1st.csv',index = True)\n",
    "x_test_2nd.to_csv('./temp_data/save_x_test_2nd.csv',index = True)\n",
    "y_test_2nd.to_csv('./temp_data/save_y_test_2nd.csv',index = True)\n",
    "\n",
    "print(train_0)\n",
    "print(train_1)\n",
    "\n",
    "print(test_1st_0)\n",
    "print(test_1st_1)\n",
    "\n",
    "print(test_2nd_0)\n",
    "print(test_2nd_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07a49ef-b987-4a17-b24a-da5a5b9e4d7a",
   "metadata": {},
   "source": [
    "## 최종 학습 데이터 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "310c02b8-147c-424e-abe4-5c1b08bdab68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    15738\n",
      "1      746\n",
      "Name: ACADEMIC_STAT_CODE, dtype: int64\n",
      "4.53 %\n",
      "None\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1970\n",
      "1      91\n",
      "Name: ACADEMIC_STAT_CODE, dtype: int64\n",
      "4.42 %\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "y_train = y_train.replace('탈락',1)\n",
    "y_train = y_train.replace('유지',0)\n",
    "\n",
    "y_test_1st = y_test_1st.replace('탈락',1)\n",
    "y_test_1st = y_test_1st.replace('유지',0)\n",
    "\n",
    "plt.hist(y_train)\n",
    "plt.xticks([0,1])\n",
    "plt.show()\n",
    "\n",
    "print(y_train.value_counts())\n",
    "print(p_100(y_train.value_counts()[1],y_train.value_counts()[0]))\n",
    "\n",
    "plt.hist(y_test_1st)\n",
    "plt.xticks([0,1])\n",
    "plt.show()\n",
    "\n",
    "print(y_test_1st.value_counts())\n",
    "print(p_100(y_test_1st.value_counts()[1],y_test_1st.value_counts()[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c16ca302-909b-4c12-ba7b-46c27c1cc43e",
   "metadata": {},
   "source": [
    "## SMOTE\n",
    " - 가장 성능을 좋게 하는 BorderlineSMOTE를 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "745dcd2f-270c-428b-ab7c-9cd6ca3ae356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# smote = SMOTE(random_state=42)\n",
    "# x_train_over,y_train_over = smote.fit_resample(x_train,y_train)\n",
    "\n",
    "# print('SMOTE 적용 전 학습용 피처/레이블 데이터 세트: ', x_train.shape, y_train.shape)\n",
    "# print('SMOTE 적용 후 학습용 피처/레이블 데이터 세트: ', x_train_over.shape, y_train_over.shape)\n",
    "\n",
    "# print('SMOTE 적용 후 레이블 값 분포: \\n', y_train_over.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6582ba17-2cac-4871-857b-b4f64b2c1fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from imblearn.over_sampling import BorderlineSMOTE\n",
    "\n",
    "# bsmote = BorderlineSMOTE(random_state=42)\n",
    "# x_train_over,y_train_over = bsmote.fit_resample(x_train,y_train)\n",
    "\n",
    "# print('BorderlineSMOTE 적용 전 학습용 피처/레이블 데이터 세트: ', x_train.shape, y_train.shape)\n",
    "# print('BorderlineSMOTE 적용 후 학습용 피처/레이블 데이터 세트: ', x_train_over.shape, y_train_over.shape)\n",
    "# print('BorderlineSMOTE 적용 후 레이블 값 분포: \\n', y_train_over.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0041db0a-2040-4f9e-af74-bdf2fabdfa08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADASYN 적용 전 학습용 피처/레이블 데이터 세트:  (16484, 37) (16484,)\n",
      "ADASYN 적용 후 학습용 피처/레이블 데이터 세트:  (31543, 37) (31543,)\n",
      "ADASYN 적용 후 레이블 값 분포: \n",
      " 1    15805\n",
      "0    15738\n",
      "Name: ACADEMIC_STAT_CODE, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import ADASYN\n",
    "\n",
    "ads = ADASYN(random_state=42)\n",
    "x_train_over,y_train_over = ads.fit_resample(x_train,y_train)\n",
    "\n",
    "print('ADASYN 적용 전 학습용 피처/레이블 데이터 세트: ', x_train.shape, y_train.shape)\n",
    "print('ADASYN 적용 후 학습용 피처/레이블 데이터 세트: ', x_train_over.shape, y_train_over.shape)\n",
    "print('ADASYN 적용 후 레이블 값 분포: \\n', y_train_over.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd55c452-052f-44c4-b584-587960003707",
   "metadata": {},
   "source": [
    "## 모델 생성\n",
    " - Ensemble : 여러 모델이 동일한 문제를 해결하고 더 나은 결과를 얻도록 훈련시키는 기계 학습 패러다임\n",
    "   - Voting : 여러 모델을 같은 데이터에 대해 학습하고 모델을 조합해서 단일 모델보다 더 나은 결과를 얻도록 하는 방식\n",
    "   - Bagging : 단일 모델에서 샘플을 여러번 뽑아(Bootstrap), 여러개의 분류기를 만들어 보팅으로 최종 결정을 하는 방식\n",
    "   - Boosting : 여러 모델이 순차적으로 학습하며 오분류된 객체에 가중치를 조절해서 예측하는 방식\n",
    "   - Stacking : 여러 모델을 결합해 예측결과를 도출하지만, 개별 모델로 예측한 데이터를 기반으로 다시 예측을 진행하는 방식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e17bdac2-9b89-4012-b359-51fd6a2c7c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier, ExtraTreesClassifier, BaggingClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1feef4-f4c4-424b-ad99-518f35d2ff07",
   "metadata": {},
   "source": [
    "#### 튜닝 전 모델 생성\n",
    " - 11개의 모델 중 종류별로 성능이 가장 좋은 모델들 중 3개만 선택해서 voting\n",
    " - Tree & Bagging : [ DecisionTreeClassifier, BaggingClassifier, RandomForestClassifier, ExtraTreesClassifier ]\n",
    " - Boosting : [ AdaBoostClassifier, GradientBoostingClassifier, XGBClassifier2014, LGBMClassifier ]\n",
    " - linear classifier : [ LogisticRegression, SVC ]\n",
    " - Nearest Neighbor : [ KNeighborsClassifier ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0830a08f-e3a8-4cbc-9000-fde4eeaa05f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier\n",
      "confusion_matrix : \n",
      "[[  14   77]\n",
      " [ 130 1840]]\n",
      "accuracy_score : 89.96\n",
      "recall_score : 15.38\n",
      "precision_score : 9.72\n",
      "f1_score : 11.91\n",
      "\n",
      "RandomForestClassifier\n",
      "confusion_matrix : \n",
      "[[   6   85]\n",
      " [  24 1946]]\n",
      "accuracy_score : 94.71\n",
      "recall_score : 6.59\n",
      "precision_score : 20.00\n",
      "f1_score : 9.92\n",
      "\n",
      "BaggingClassifier\n",
      "confusion_matrix : \n",
      "[[   7   84]\n",
      " [  34 1936]]\n",
      "accuracy_score : 94.27\n",
      "recall_score : 7.69\n",
      "precision_score : 17.07\n",
      "f1_score : 10.61\n",
      "\n",
      "ExtraTreesClassifier\n",
      "confusion_matrix : \n",
      "[[   8   83]\n",
      " [  35 1935]]\n",
      "accuracy_score : 94.27\n",
      "recall_score : 8.79\n",
      "precision_score : 18.60\n",
      "f1_score : 11.94\n",
      "\n",
      "AdaBoostClassifier\n",
      "confusion_matrix : \n",
      "[[  24   67]\n",
      " [ 166 1804]]\n",
      "accuracy_score : 88.69\n",
      "recall_score : 26.37\n",
      "precision_score : 12.63\n",
      "f1_score : 17.08\n",
      "\n",
      "GradientBoostingClassifier\n",
      "confusion_matrix : \n",
      "[[   4   87]\n",
      " [   3 1967]]\n",
      "accuracy_score : 95.63\n",
      "recall_score : 4.40\n",
      "precision_score : 57.14\n",
      "f1_score : 8.16\n",
      "\n",
      "XGBClassifier\n",
      "confusion_matrix : \n",
      "[[   5   86]\n",
      " [  12 1958]]\n",
      "accuracy_score : 95.25\n",
      "recall_score : 5.49\n",
      "precision_score : 29.41\n",
      "f1_score : 9.26\n",
      "\n",
      "LGBMClassifier\n",
      "confusion_matrix : \n",
      "[[   5   86]\n",
      " [   7 1963]]\n",
      "accuracy_score : 95.49\n",
      "recall_score : 5.49\n",
      "precision_score : 41.67\n",
      "f1_score : 9.71\n",
      "\n",
      "LogisticRegression\n",
      "confusion_matrix : \n",
      "[[  49   42]\n",
      " [ 526 1444]]\n",
      "accuracy_score : 72.44\n",
      "recall_score : 53.85\n",
      "precision_score : 8.52\n",
      "f1_score : 14.71\n",
      "\n",
      "SVC\n",
      "confusion_matrix : \n",
      "[[  48   43]\n",
      " [ 518 1452]]\n",
      "accuracy_score : 72.78\n",
      "recall_score : 52.75\n",
      "precision_score : 8.48\n",
      "f1_score : 14.61\n",
      "\n",
      "KNeighborsClassifier\n",
      "confusion_matrix : \n",
      "[[  23   68]\n",
      " [ 291 1679]]\n",
      "accuracy_score : 82.58\n",
      "recall_score : 25.27\n",
      "precision_score : 7.32\n",
      "f1_score : 11.36\n",
      "\n",
      "VotingClassifier  : LogisticRegression(random_state=42) , AdaBoostClassifier(random_state=42) , KNeighborsClassifier() , \n",
      "confusion_matrix : \n",
      "[[  25   66]\n",
      " [ 268 1702]]\n",
      "recall_score : 27.47\n",
      "precision_score : 8.53\n",
      "f1_score : 13.02\n",
      "\n",
      "289.82278 sec\n"
     ]
    }
   ],
   "source": [
    "start = time.time() \n",
    "\n",
    "dt_clf = DecisionTreeClassifier(random_state=42)\n",
    "rf_clf = RandomForestClassifier(random_state=42)\n",
    "ada_clf = AdaBoostClassifier(random_state=42)\n",
    "xtree_clf = ExtraTreesClassifier(random_state=42)\n",
    "bag_clf = BaggingClassifier(random_state=42)\n",
    "gdb_clf = GradientBoostingClassifier(random_state=42)\n",
    "log_clf = LogisticRegression(random_state=42)\n",
    "#ridge_clf = RidgeClassifier(random_state=42)\n",
    "svm_clf = SVC(kernel='linear', probability=True, random_state=42)\n",
    "knn_clf = KNeighborsClassifier()\n",
    "xgb_clf = XGBClassifier(eval_metric='mlogloss', random_state=42)\n",
    "lgb_clf = LGBMClassifier(random_state=42)\n",
    "\n",
    "Tree_Bagging = [dt_clf, rf_clf, bag_clf, xtree_clf]\n",
    "Boosting = [ada_clf, gdb_clf, xgb_clf, lgb_clf]\n",
    "linear = [log_clf, svm_clf]\n",
    "Neighbor = [knn_clf]\n",
    "\n",
    "mldel_list = [Tree_Bagging, Boosting, linear, Neighbor]\n",
    "top_list = []\n",
    "for ml in mldel_list:\n",
    "    clf_list = ml.copy()\n",
    "    temp_list = []\n",
    "\n",
    "    for clf in clf_list:\n",
    "        clf.fit(x_train_over, y_train_over)\n",
    "        y_pred = clf.predict(x_test_1st)\n",
    "        cf = confusion_matrix(y_test_1st, y_pred, labels=[1, 0])\n",
    "        print(clf.__class__.__name__)\n",
    "        print(\"confusion_matrix : \")\n",
    "        print(cf)\n",
    "        print(\"accuracy_score : {:.2f}\".format(accuracy_score(y_test_1st,y_pred)*100))\n",
    "        print(\"recall_score : {:.2f}\".format(recall_score(y_test_1st,y_pred,labels=[1, 0])*100))\n",
    "        print(\"precision_score : {:.2f}\".format(precision_score(y_test_1st,y_pred,labels=[1, 0])*100))\n",
    "        print(\"f1_score : {:.2f}\".format(f1_score(y_test_1st,y_pred,labels=[1, 0])*100))\n",
    "        print()\n",
    "        temp_list.append([clf, recall_score(y_test_1st,y_pred,labels=[1, 0])*100])\n",
    "        temp_list.sort(key=lambda x: (-x[1]))\n",
    "        \n",
    "    top_list.append(temp_list[0])\n",
    "\n",
    "top_list.sort(key=lambda x: (-x[1]))\n",
    "top_list.pop()\n",
    "\n",
    "top_estimators = [('top1', top_list[0][0]),\n",
    "               ('top2', top_list[1][0]),\n",
    "               ('top3', top_list[2][0])]\n",
    "\n",
    "voting_clf = VotingClassifier(estimators=top_estimators, voting='soft')\n",
    "\n",
    "voting_clf.fit(x_train_over, y_train_over)\n",
    "y_pred = voting_clf.predict(x_test_1st)\n",
    "cf = confusion_matrix(y_test_1st, y_pred, labels=[1, 0])\n",
    "print(voting_clf.__class__.__name__,\" : \", end='')\n",
    "for element in top_estimators:\n",
    "    print(element[1], \", \", end='')\n",
    "    if element[1] == top_list[2][0]:\n",
    "        print()\n",
    "\n",
    "print(\"confusion_matrix : \")\n",
    "print(cf)\n",
    "print(\"recall_score : {:.2f}\".format(recall_score(y_test_1st,y_pred,labels=[1, 0])*100))\n",
    "print(\"precision_score : {:.2f}\".format(precision_score(y_test_1st,y_pred,labels=[1, 0])*100))\n",
    "print(\"f1_score : {:.2f}\".format(f1_score(y_test_1st,y_pred,labels=[1, 0])*100))\n",
    "print()  \n",
    "    \n",
    "end = time.time()     \n",
    "print(f\"{end - start:.5f} sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e60954c-f479-4c54-959d-237dfe5234af",
   "metadata": {},
   "source": [
    "#### 모델 튜닝\n",
    " - 튜닝을 통해 가장 성능이 좋은 모델 3개를 voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35e1f4c3-89c3-4b34-b041-150006faeb20",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DecisionTreeClassifier(random_state=42), RandomForestClassifier(random_state=42), BaggingClassifier(random_state=42), ExtraTreesClassifier(random_state=42)]\n",
      "DecisionTreeClassifier(random_state=42)\n",
      "[{'min_samples_split': [2, 5, 8], 'max_depth': [None, 5, 15, 25], 'random_state': [42]}]\n",
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "The best parameter for DecisionTreeClassifier is {'max_depth': None, 'min_samples_split': 2, 'random_state': 42} with a runtime of 5.23 seconds.\n",
      "confusion_matrix : \n",
      "[[  14   77]\n",
      " [ 130 1840]]\n",
      "recall_score : 15.38\n",
      "precision_score : 9.72\n",
      "f1_score : 11.91\n",
      "\n",
      "RandomForestClassifier(random_state=42)\n",
      "[{'min_samples_split': [2, 5, 8], 'max_depth': [None, 5, 15, 25], 'random_state': [42]}]\n",
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "The best parameter for RandomForestClassifier is {'max_depth': 25, 'min_samples_split': 2, 'random_state': 42} with a runtime of 86.15 seconds.\n",
      "confusion_matrix : \n",
      "[[   6   85]\n",
      " [  23 1947]]\n",
      "recall_score : 6.59\n",
      "precision_score : 20.69\n",
      "f1_score : 10.00\n",
      "\n",
      "BaggingClassifier(random_state=42)\n",
      "[{'n_estimators': [10, 50, 100, 150], 'max_samples': [1, 5, 10], 'random_state': [42]}]\n",
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "The best parameter for BaggingClassifier is {'max_samples': 1, 'n_estimators': 10, 'random_state': 42} with a runtime of 19.03 seconds.\n",
      "confusion_matrix : \n",
      "[[   0   91]\n",
      " [   0 1970]]\n",
      "recall_score : 0.00\n",
      "precision_score : 0.00\n",
      "f1_score : 0.00\n",
      "\n",
      "ExtraTreesClassifier(random_state=42)\n",
      "[{'n_estimators': [10, 50, 100, 150], 'min_samples_split': [2, 5, 8], 'max_depth': [None, 5, 15, 25], 'random_state': [42]}]\n",
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n",
      "The best parameter for ExtraTreesClassifier is {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 150, 'random_state': 42} with a runtime of 158.26 seconds.\n",
      "confusion_matrix : \n",
      "[[   8   83]\n",
      " [  38 1932]]\n",
      "recall_score : 8.79\n",
      "precision_score : 17.39\n",
      "f1_score : 11.68\n",
      "\n",
      "[AdaBoostClassifier(random_state=42), GradientBoostingClassifier(random_state=42), XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, eval_metric='mlogloss', gamma=None,\n",
      "              gpu_id=None, importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=42, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None), LGBMClassifier(random_state=42)]\n",
      "AdaBoostClassifier(random_state=42)\n",
      "[{'n_estimators': [10, 50, 100, 150], 'learning_rate': [0.1, 1, 10], 'random_state': [42]}]\n",
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "The best parameter for AdaBoostClassifier is {'learning_rate': 1, 'n_estimators': 150, 'random_state': 42} with a runtime of 73.75 seconds.\n",
      "confusion_matrix : \n",
      "[[   4   87]\n",
      " [  14 1956]]\n",
      "recall_score : 4.40\n",
      "precision_score : 22.22\n",
      "f1_score : 7.34\n",
      "\n",
      "GradientBoostingClassifier(random_state=42)\n",
      "[{'n_estimators': [10, 50, 100, 150], 'max_depth': [None, 5, 15, 25], 'random_state': [42]}]\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "The best parameter for GradientBoostingClassifier is {'max_depth': 5, 'n_estimators': 150, 'random_state': 42} with a runtime of 875.24 seconds.\n",
      "confusion_matrix : \n",
      "[[   7   84]\n",
      " [   1 1969]]\n",
      "recall_score : 7.69\n",
      "precision_score : 87.50\n",
      "f1_score : 14.14\n",
      "\n",
      "XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              enable_categorical=False, eval_metric='mlogloss', gamma=None,\n",
      "              gpu_id=None, importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
      "              predictor=None, random_state=42, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              validate_parameters=None, verbosity=None)\n",
      "[{'n_estimators': [10, 50, 100, 150], 'max_depth': [None, 5, 15, 25], 'seed': [42]}]\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "The best parameter for XGBClassifier is {'max_depth': 15, 'n_estimators': 150, 'seed': 42} with a runtime of 137.67 seconds.\n",
      "confusion_matrix : \n",
      "[[   7   84]\n",
      " [  28 1942]]\n",
      "recall_score : 7.69\n",
      "precision_score : 20.00\n",
      "f1_score : 11.11\n",
      "\n",
      "LGBMClassifier(random_state=42)\n",
      "[{'n_estimators': [10, 50, 100, 150], 'max_depth': [None, 5, 15, 25], 'seed': [42]}]\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "[LightGBM] [Warning] seed is set=42, random_state=42 will be ignored. Current value: seed=42\n",
      "[LightGBM] [Warning] seed is set=42, random_state=42 will be ignored. Current value: seed=42\n",
      "[LightGBM] [Warning] seed is set=42, random_state=42 will be ignored. Current value: seed=42\n",
      "[LightGBM] [Warning] seed is set=42, random_state=42 will be ignored. Current value: seed=42\n",
      "[LightGBM] [Warning] seed is set=42, random_state=42 will be ignored. Current value: seed=42\n",
      "[LightGBM] [Warning] seed is set=42, random_state=42 will be ignored. Current value: seed=42\n",
      "[LightGBM] [Warning] seed is set=42, random_state=42 will be ignored. Current value: seed=42\n",
      "[LightGBM] [Warning] seed is set=42, random_state=42 will be ignored. Current value: seed=42\n",
      "[LightGBM] [Warning] seed is set=42, random_state=42 will be ignored. Current value: seed=42\n",
      "[LightGBM] [Warning] seed is set=42, random_state=42 will be ignored. Current value: seed=42\n",
      "[LightGBM] [Warning] seed is set=42, random_state=42 will be ignored. Current value: seed=42\n",
      "[LightGBM] [Warning] seed is set=42, random_state=42 will be ignored. Current value: seed=42\n",
      "[LightGBM] [Warning] seed is set=42, random_state=42 will be ignored. Current value: seed=42\n",
      "[LightGBM] [Warning] seed is set=42, random_state=42 will be ignored. Current value: seed=42\n",
      "[LightGBM] [Warning] seed is set=42, random_state=42 will be ignored. Current value: seed=42\n",
      "[LightGBM] [Warning] seed is set=42, random_state=42 will be ignored. Current value: seed=42\n",
      "[LightGBM] [Warning] seed is set=42, random_state=42 will be ignored. Current value: seed=42\n",
      "[LightGBM] [Warning] seed is set=42, random_state=42 will be ignored. Current value: seed=42\n",
      "[LightGBM] [Warning] seed is set=42, random_state=42 will be ignored. Current value: seed=42\n",
      "[LightGBM] [Warning] seed is set=42, random_state=42 will be ignored. Current value: seed=42\n",
      "[LightGBM] [Warning] seed is set=42, random_state=42 will be ignored. Current value: seed=42\n",
      "[LightGBM] [Warning] seed is set=42, random_state=42 will be ignored. Current value: seed=42\n",
      "[LightGBM] [Warning] seed is set=42, random_state=42 will be ignored. Current value: seed=42\n",
      "[LightGBM] [Warning] seed is set=42, random_state=42 will be ignored. Current value: seed=42\n",
      "[LightGBM] [Warning] seed is set=42, random_state=42 will be ignored. Current value: seed=42\n",
      "[LightGBM] [Warning] seed is set=42, random_state=42 will be ignored. Current value: seed=42\n",
      "[LightGBM] [Warning] seed is set=42, random_state=42 will be ignored. Current value: seed=42\n",
      "[LightGBM] [Warning] seed is set=42, random_state=42 will be ignored. Current value: seed=42\n",
      "[LightGBM] [Warning] seed is set=42, random_state=42 will be ignored. Current value: seed=42\n",
      "[LightGBM] [Warning] seed is set=42, random_state=42 will be ignored. Current value: seed=42\n",
      "[LightGBM] [Warning] seed is set=42, random_state=42 will be ignored. Current value: seed=42\n",
      "[LightGBM] [Warning] seed is set=42, random_state=42 will be ignored. Current value: seed=42\n",
      "[LightGBM] [Warning] seed is set=42, random_state=42 will be ignored. Current value: seed=42\n",
      "[LightGBM] [Warning] seed is set=42, random_state=42 will be ignored. Current value: seed=42\n",
      "[LightGBM] [Warning] seed is set=42, random_state=42 will be ignored. Current value: seed=42\n",
      "[LightGBM] [Warning] seed is set=42, random_state=42 will be ignored. Current value: seed=42\n",
      "[LightGBM] [Warning] seed is set=42, random_state=42 will be ignored. Current value: seed=42\n",
      "[LightGBM] [Warning] seed is set=42, random_state=42 will be ignored. Current value: seed=42\n",
      "[LightGBM] [Warning] seed is set=42, random_state=42 will be ignored. Current value: seed=42\n",
      "[LightGBM] [Warning] seed is set=42, random_state=42 will be ignored. Current value: seed=42\n",
      "[LightGBM] [Warning] seed is set=42, random_state=42 will be ignored. Current value: seed=42\n",
      "[LightGBM] [Warning] seed is set=42, random_state=42 will be ignored. Current value: seed=42\n",
      "[LightGBM] [Warning] seed is set=42, random_state=42 will be ignored. Current value: seed=42\n",
      "[LightGBM] [Warning] seed is set=42, random_state=42 will be ignored. Current value: seed=42\n",
      "[LightGBM] [Warning] seed is set=42, random_state=42 will be ignored. Current value: seed=42\n",
      "[LightGBM] [Warning] seed is set=42, random_state=42 will be ignored. Current value: seed=42\n",
      "[LightGBM] [Warning] seed is set=42, random_state=42 will be ignored. Current value: seed=42\n",
      "[LightGBM] [Warning] seed is set=42, random_state=42 will be ignored. Current value: seed=42\n",
      "[LightGBM] [Warning] seed is set=42, random_state=42 will be ignored. Current value: seed=42\n",
      "The best parameter for LGBMClassifier is {'max_depth': None, 'n_estimators': 150, 'seed': 42} with a runtime of 20.02 seconds.\n",
      "confusion_matrix : \n",
      "[[   5   86]\n",
      " [   6 1964]]\n",
      "recall_score : 5.49\n",
      "precision_score : 45.45\n",
      "f1_score : 9.80\n",
      "\n",
      "[LogisticRegression(random_state=42), SVC(kernel='linear', probability=True, random_state=42)]\n",
      "LogisticRegression(random_state=42)\n",
      "[{'C': [0.1, 1, 10, 100], 'fit_intercept': [True, False], 'penalty': ['l1', 'l2'], 'random_state': [42]}]\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "The best parameter for LogisticRegression is {'C': 100, 'fit_intercept': False, 'penalty': 'l2', 'random_state': 42} with a runtime of 4.65 seconds.\n",
      "confusion_matrix : \n",
      "[[  53   38]\n",
      " [ 592 1378]]\n",
      "recall_score : 58.24\n",
      "precision_score : 8.22\n",
      "f1_score : 14.40\n",
      "\n",
      "SVC(kernel='linear', probability=True, random_state=42)\n",
      "[{'C': [0.1, 1, 10, 100], 'random_state': [42]}]\n",
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "The best parameter for SVC is {'C': 100, 'random_state': 42} with a runtime of 2377.33 seconds.\n",
      "confusion_matrix : \n",
      "[[  54   37]\n",
      " [ 533 1437]]\n",
      "recall_score : 59.34\n",
      "precision_score : 9.20\n",
      "f1_score : 15.93\n",
      "\n",
      "[KNeighborsClassifier()]\n",
      "KNeighborsClassifier()\n",
      "[{'n_neighbors': [2, 5, 6, 10], 'p': [1, 2]}]\n",
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "The best parameter for KNeighborsClassifier is {'n_neighbors': 5, 'p': 1} with a runtime of 149.40 seconds.\n",
      "confusion_matrix : \n",
      "[[  19   72]\n",
      " [ 203 1767]]\n",
      "recall_score : 20.88\n",
      "precision_score : 8.56\n",
      "f1_score : 12.14\n",
      "\n",
      "VotingClassifier  : SVC(C=100, kernel='linear', probability=True, random_state=42) , KNeighborsClassifier(p=1) , DecisionTreeClassifier(random_state=42) , \n",
      "confusion_matrix : \n",
      "[[  15   76]\n",
      " [ 107 1863]]\n",
      "recall_score : 16.48\n",
      "precision_score : 12.30\n",
      "f1_score : 14.08\n",
      "\n",
      "4670.66514 sec\n"
     ]
    }
   ],
   "source": [
    "start = time.time() \n",
    "\n",
    "dt_clf = DecisionTreeClassifier(random_state=42)\n",
    "rf_clf = RandomForestClassifier(random_state=42)\n",
    "ada_clf = AdaBoostClassifier(random_state=42)\n",
    "xtree_clf = ExtraTreesClassifier(random_state=42)\n",
    "bag_clf = BaggingClassifier(random_state=42)\n",
    "gdb_clf = GradientBoostingClassifier(random_state=42)\n",
    "log_clf = LogisticRegression(random_state=42)\n",
    "svm_clf = SVC(kernel='linear', probability=True, random_state=42)\n",
    "xgb_clf = XGBClassifier(eval_metric='mlogloss', random_state=42)\n",
    "lgb_clf = LGBMClassifier(random_state=42)\n",
    "knn_clf = KNeighborsClassifier()\n",
    "\n",
    "Tree_Bagging = [dt_clf, rf_clf, bag_clf, xtree_clf]\n",
    "Boosting = [ada_clf, gdb_clf, xgb_clf, lgb_clf]\n",
    "linear = [log_clf, svm_clf]\n",
    "Neighbor = [knn_clf]\n",
    "\n",
    "grid_n_estimator = [10, 50, 100, 150]\n",
    "grid_max_depth = [None, 5, 15, 25]\n",
    "grid_min_samples = [2, 5, 8]\n",
    "grid_c = [0.1, 1, 10, 100]\n",
    "grid_learn = [0.1, 1, 10]\n",
    "grid_bool = [True, False]\n",
    "grid_seed = [42]\n",
    "\n",
    "Tree_Bagging_grid_param = [\n",
    "                         [{\n",
    "                        #DecisionTreeClassifier\n",
    "                        'min_samples_split': grid_min_samples, #default=2\n",
    "                        'max_depth': grid_max_depth, #default=None\n",
    "                        'random_state': grid_seed\n",
    "                         }],\n",
    "                         [{\n",
    "                        #RandomForestClassifier\n",
    "                        'min_samples_split': grid_min_samples, #default=2\n",
    "                        'max_depth': grid_max_depth, #default=None\n",
    "                        'random_state': grid_seed\n",
    "                         }],\n",
    "                        [{\n",
    "                        #BaggingClassifier \n",
    "                        'n_estimators': grid_n_estimator, #default=10\n",
    "                        'max_samples': [1, 5, 10], #default=1.0\n",
    "                        'random_state': grid_seed\n",
    "                         }],\n",
    "                        [{\n",
    "                        #ExtraTreesClassifier \n",
    "                        'n_estimators': grid_n_estimator, #default=100\n",
    "                        'min_samples_split': grid_min_samples, #default=2    \n",
    "                        'max_depth': grid_max_depth, #default=None\n",
    "                        'random_state': grid_seed\n",
    "                         }],\n",
    "                        ]\n",
    "Boosting_grid_param = [\n",
    "                    [{\n",
    "                    #AdaBoostClassifier\n",
    "                    'n_estimators': grid_n_estimator, #default=50\n",
    "                    'learning_rate': grid_learn, #default=1\n",
    "                    'random_state': grid_seed\n",
    "                    }],\n",
    "                    [{\n",
    "                    #GradientBoostingClassifier \n",
    "                    'n_estimators': grid_n_estimator, #default=100\n",
    "                    #'min_samples_split': grid_min_samples, #default=2  \n",
    "                    'max_depth': grid_max_depth, #default=3 \n",
    "                    #'learning_rate': grid_learn, #default=0.1    \n",
    "                    'random_state': grid_seed\n",
    "                     }],\n",
    "                    [{\n",
    "                    #XGBClassifier\n",
    "                    'n_estimators': grid_n_estimator, \n",
    "                    'max_depth': grid_max_depth,\n",
    "                    'seed': grid_seed  \n",
    "                     }],\n",
    "                    [{\n",
    "                    #LGBMClassifier -\n",
    "                    'n_estimators': grid_n_estimator, \n",
    "                    'max_depth': grid_max_depth,\n",
    "                    'seed': grid_seed   \n",
    "                    }]\n",
    "                    ]\n",
    "linear_grid_param = [\n",
    "                    [{\n",
    "                    #LogisticRegressionCV \n",
    "                    'C': grid_c, #default=1\n",
    "                    'fit_intercept': grid_bool, #default: True\n",
    "                    'penalty': ['l1','l2'],\n",
    "                    'random_state': grid_seed\n",
    "                     }],\n",
    "                    [{\n",
    "                    #SVC \n",
    "                    'C': grid_c, #default=1.0\n",
    "                    'random_state': grid_seed\n",
    "                     }]\n",
    "                    ]\n",
    "Neighbor_grid_param = [\n",
    "                    [{\n",
    "                    #KNeighborsClassifier \n",
    "                    'n_neighbors': [2,5,6,10], #default: 5\n",
    "                    'p':[1,2]\n",
    "                    }],\n",
    "                    ]\n",
    "\n",
    "\n",
    "\n",
    "mldel_list = [Tree_Bagging, Boosting, linear, Neighbor]\n",
    "param_list = [Tree_Bagging_grid_param, Boosting_grid_param, linear_grid_param, Neighbor_grid_param]\n",
    "\n",
    "top_list = []\n",
    "for ml, grid_param in zip(mldel_list, param_list):\n",
    "    clf_list = ml.copy()\n",
    "    print(clf_list)\n",
    "    temp_list = []\n",
    "\n",
    "    for clf, param in zip(clf_list,grid_param):\n",
    "        param_start = time.time() \n",
    "        print(clf)\n",
    "        print(param)\n",
    "        grid_cv = GridSearchCV(estimator=clf, param_grid=param, scoring='recall', cv=3, verbose=1)\n",
    "        grid_cv.fit(x_train_over, y_train_over)\n",
    "        best_param = grid_cv.best_params_     \n",
    "        clf.set_params(**best_param)\n",
    "        y_pred = grid_cv.predict(x_test_1st)\n",
    "\n",
    "        param_end = time.time()\n",
    "        run = param_end - param_start\n",
    "\n",
    "        print('The best parameter for {} is {} with a runtime of {:.2f} seconds.'.format(clf.__class__.__name__, best_param, run))\n",
    "        cf = confusion_matrix(y_test_1st, y_pred, labels=[1, 0])\n",
    "        print(\"confusion_matrix : \")\n",
    "        print(cf)\n",
    "        print(\"recall_score : {:.2f}\".format(recall_score(y_test_1st,y_pred,labels=[1, 0])*100))\n",
    "        print(\"precision_score : {:.2f}\".format(precision_score(y_test_1st,y_pred,labels=[1, 0])*100))\n",
    "        print(\"f1_score : {:.2f}\".format(f1_score(y_test_1st,y_pred,labels=[1, 0])*100))\n",
    "        print()\n",
    "        temp_list.append([clf, recall_score(y_test_1st,y_pred,labels=[1, 0])*100])\n",
    "        temp_list.sort(key=lambda x: (-x[1]))\n",
    "    top_list.append(temp_list[0])\n",
    "    \n",
    "top_list.sort(key=lambda x: (-x[1]))\n",
    "top_list.pop()\n",
    "\n",
    "top_estimators = [('top1', top_list[0][0]),\n",
    "               ('top2', top_list[1][0]),\n",
    "               ('top3', top_list[2][0])]\n",
    "\n",
    "\n",
    "voting_clf = VotingClassifier(estimators=top_estimators, voting='soft')\n",
    "\n",
    "best_clf = voting_clf.fit(x_train_over, y_train_over)\n",
    "y_pred = best_clf.predict(x_test_1st)\n",
    "cf = confusion_matrix(y_test_1st, y_pred, labels=[1, 0])\n",
    "print(voting_clf.__class__.__name__,\" : \", end='')\n",
    "for element in top_estimators:\n",
    "    print(element[1], \", \", end='')\n",
    "    if element[1] == top_list[2][0]:\n",
    "        print()\n",
    "\n",
    "print(\"confusion_matrix : \")\n",
    "print(cf)\n",
    "print(\"recall_score : {:.2f}\".format(recall_score(y_test_1st,y_pred,labels=[1, 0])*100))\n",
    "print(\"precision_score : {:.2f}\".format(precision_score(y_test_1st,y_pred,labels=[1, 0])*100))\n",
    "print(\"f1_score : {:.2f}\".format(f1_score(y_test_1st,y_pred,labels=[1, 0])*100))\n",
    "print()  \n",
    "    \n",
    "end = time.time()     \n",
    "print(f\"{end - start:.5f} sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02a1784-4196-451c-b5e4-0b76bd86ae6c",
   "metadata": {},
   "source": [
    "## 모델 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5946ab69-ee43-4a05-a99e-690b0198d011",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('./model/student_model_test.pickle','wb') as fw:\n",
    "    pickle.dump(best_clf, fw)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
